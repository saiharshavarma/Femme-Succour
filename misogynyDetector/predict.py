# -*- coding: utf-8 -*-
"""Sexism Misogyny Detect WECode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pygAZxK18g8I0HkS2XNTezfpeobd-Hjt
"""

import pandas as pd
import numpy as np

# Commented out IPython magic to ensure Python compatibility.
# %pip install cohere

data = pd.read_csv('misogynyDetector/sexism-Data final.csv')

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC

# Convert text data into numerical feature vectors using TfidfVectorizer
vectorizer = TfidfVectorizer()

# Train an SVM model on the training data
model = LinearSVC()

from sklearn.svm import SVR

vectorizer = TfidfVectorizer()
vectors = vectorizer.fit_transform(data['text'])

model = SVR()
model.fit(vectors, data['toxicity'])

# Predict the toxicity level of new text
def xyz(text):
    new_text = text
    new_vector = vectorizer.transform([new_text])
    toxicity_level = model.predict(new_vector)[0]
    print("Toxicity level: {:.2f}%".format(toxicity_level * 100))
    return toxicity_level

import pickle
pickle.dump(model, open('model.pkl', 'wb'))